#ifndef CM_OURS_H
#define CM_OURS_H
// #define ATOMIC
#include "../template/Ours.h"
#include "CM.h"
#include "config.h"
#include <chrono>
#include <cstdint>
#include <numa.h>
#include <sys/types.h>
/**
 * OctoSketch for the Count-Min sketch
 */
// implementation for direct write

template <typename Key, uint32_t thread_num>
class CM_Ours : public Ours<Key, CM_Entry<Key>, thread_num>
{
public:
  typedef ReaderWriterQueue<CM_Entry<Key>> myQueue;
  typedef ReaderWriterQueue<Heap_entry<Key>> heapQueue;
  Sketch<Key> *initialize_parent() { return new MyCM<Key>(); }

  Sketch<Key> *initialize_child() { return new MyChild_CM<Key>(); }

  void
  insert_child(Sketch<Key> *p, myQueue q_group[][thread_num],
               const Key &packet,
               //  Heap<Key, int32_t>& heap,
               //  uint64_t test,
               uint64_t thread_id,
               struct global_sketch_sub_section *sketch_sub_section)
  {
    double hit_rate;
    uint64_t local_min;
    auto sketch = ((MyChild_CM<Key> *)p)->sketch;
    uint32_t pos[HASH_NUM];
    for (uint32_t hashPos = 0; hashPos < HASH_NUM; ++hashPos)
    {
      pos[hashPos] = hash(packet, hashPos) % LENGTH;
    }

    for (uint32_t hashPos = 0; hashPos < HASH_NUM; ++hashPos)
    {
      sketch[hashPos][pos[hashPos]] += 1;

      if (sketch[hashPos][pos[hashPos]] >= PROMASK)
      {
        // std::cout << "yes" << std::endl;

        uint64_t push_sec_id = pos[hashPos] / sub_sketch_length;
        uint16_t sec_inner_index = pos[hashPos] % sub_sketch_length;
        // if(push_sec_id >= thread_num)
        // {
        //   std::cout << pos[hashPos]<<std::endl;
        //   std::cout << sub_sketch_length;
        //   std::cout <<"access error"<<std::endl;
        // }

        while(!q_group[push_sec_id][thread_id].enqueue_fast(CM_Entry<Key>(packet, hashPos, sec_inner_index, sketch[hashPos][pos[hashPos]])))
        {
          process_queue(q_group,sketch_sub_section,this->heap,&(this->heap_que[thread_id]),thread_id);
        }
        // q_group[push_sec_id][thread_id].enqueue(CM_Entry<Key>(packet, hashPos, sec_inner_index, sketch[hashPos][pos[hashPos]]));
        // if (thread_id < push_sec_id)
        // {
        //   q_group[push_sec_id][thread_id].enqueue(CM_Entry<Key>(
        //       packet, hashPos, sec_inner_index, sketch[hashPos][pos[hashPos]]));
        // }
        // else if (push_sec_id == thread_id)
        // { // direct write to global sketch
        //   uint64_t counter_pos = hashPos * sub_sketch_length + sec_inner_index;
        //   sketch_sub_section[thread_id].counter[counter_pos] += sketch[hashPos][pos[hashPos]];
        //   // this->merge_cnt[thread_id].value++;
        //   // sketch_sub_section
        //   // ->counter[hashPos * sub_sketch_length + sec_inner_index] +=
        //   // sketch[hashPos][pos[hashPos]];
        //   // sketch_sub_section->counter[hashPos * sub_sketch_length + sec_inner_index] += sketch[hashPos][pos[hashPos]];
        //   // if(sketch_sub_section[thread_id].counter[counter_pos]> this->local_min[thread_id].value)
        //   // {
        //   //   this->merge_cnt[thread_id].value++;
        //   //   int32_t minimum = sketch_sub_section[thread_id].counter[counter_pos];
        //   //   for (uint32_t tempHash = 0; tempHash < HASH_NUM; ++tempHash) {
        //   //     uint64_t push_sec_id = pos[tempHash] / sub_sketch_length;
        //   //     uint16_t sec_inner_index = pos[tempHash] % sub_sketch_length;
        //   //     minimum = MIN(minimum,sketch_sub_section[push_sec_id].counter[tempHash * sub_sketch_length+sec_inner_index]);
        //   //   }
        //   //   this->my_minimum[thread_id].value = minimum;
        //   //   // if(minimum > this->local_min[thread_id].value)
        //   //   //   this->heap_que[thread_id].enqueue(Heap_entry<Key>(packet,minimum));
        //   // }
        // }
        // else
        // {
        //   q_group[push_sec_id][thread_id - 1].enqueue(CM_Entry<Key>(
        //       packet, hashPos, sec_inner_index, sketch[hashPos][pos[hashPos]]));
        // }
        // this->merge_cnt[push_sec_id].value++;
        // process_queue(q_group, sketch_sub_section);
        sketch[hashPos][pos[hashPos]] = 0;
      }
    }
    // process_queue(q_group, sketch_sub_section, thread_id);
  }

  // inline void direct_write(struct global_sketch_sub_section *sketch_sub_section, uint16_t&  )

  void process_queue(myQueue q_group[][thread_num],
                     struct global_sketch_sub_section *sketch_sub_section,
                     Heap<Key, int32_t> *heap, heapQueue *heap_que,
                     //  uint64_t& local_min ,uint64_t& round,
                     uint64_t thread_id = 0)
  {
    CM_Entry<Key> temp;
    uint64_t que_cnt = 0;
    uint64_t candidate_cnt = 0;
    uint64_t cnt = 0;
    // std::cout<<"yes"<<std::endl;
    // uint64_t local_min = 0;
    for (uint64_t i = 0; i < thread_num; i++)
    {
      while (q_group[thread_id][i].try_dequeue(temp))
      {
        // direct write to global sketch
        const uint16_t &hash_pos = temp.hashPos;
        const uint16_t &pos = temp.pos;
        uint64_t counter_pos = hash_pos * sub_sketch_length + pos;
#ifndef ATOMIC
        sketch_sub_section[thread_id].counter[counter_pos] +=
            temp.value;
        if (sketch_sub_section[thread_id].counter[counter_pos] > this->local_min[thread_id].value)
#else
        sketch_sub_section[thread_id].counter[counter_pos].fetch_add(temp.value);
        uint64_t counter_val =  sketch_sub_section[thread_id].counter[counter_pos].load();
        if (counter_val > this->local_min[thread_id].value)
#endif
        {
          // if (cnt == 0 && this->round[thread_id].value <= 100)
          //   this->local_min[thread_id].value = heap->min();
          // else 
          candidate_cnt ++;
          if(cnt == 0 && this->round[thread_id].value%9 == 0)
            this->local_min[thread_id].value = heap->min();
#ifndef ATOMIC
            int32_t minimum = sketch_sub_section[thread_id].counter[counter_pos];
#else 
            int32_t minimum = counter_val;
#endif
          int32_t origin_min = minimum;
          // uint64_t candidate = 0;
          // uint64_t min_hash_pos = hash_pos;
          for (uint32_t tempHash = 0; tempHash < HASH_NUM; ++tempHash)
          {
            uint32_t tempPos = hash(temp.key, tempHash) % LENGTH;
            uint64_t push_sec_id = tempPos / sub_sketch_length;
            uint16_t sec_inner_index = tempPos % sub_sketch_length;
            // candidate = sketch_sub_section[push_sec_id].counter[tempHash * sub_sketch_length + sec_inner_index];
            // if(minimum > candidate)
            // {
            //   minimum = candidate;
            //   min_hash_pos = tempHash;
            // }
#ifndef ATOMIC
            minimum = MIN(minimum, sketch_sub_section[push_sec_id].counter[tempHash * sub_sketch_length + sec_inner_index]);
#else
            minimum = MIN(minimum, sketch_sub_section[push_sec_id].counter[tempHash * sub_sketch_length + sec_inner_index].load());
#endif
          }
          // this->my_minimum[thread_id].value = minimum;
          // if(min_hash_pos == hash_pos)
          //   heap_que->enqueue(Heap_entry<Key>(temp.key, minimum));
          if (__builtin_expect(minimum == origin_min, 1))
          // if (__builtin_expect(minimum > this->local_min[thread_id].value, 1))
          // if (minimum > this->local_min[thread_id].value)
          {
            que_cnt++;
            // bool flag = heap_que->enqueue(Heap_entry<Key>(temp.key,minimum));
            heap_que->enqueue(Heap_entry<Key>(temp.key, minimum));
            // if(!flag)
            //   this->expansion_round[thread_id].push_back(round);
          }
          cnt++;
        }
      }
    }
    this->round[thread_id].value++;
    // this->process_cnt[thread_id].push_back(cnt);
    // if(candidate_cnt!=0)
    // this->process_cnt[thread_id].push_back((double)que_cnt/candidate_cnt);
  }
  void merge(Sketch<Key> *p, CM_Entry<Key> temp)
  {
    ((MyCM<Key> *)p)->Merge(temp);
  }
};

#endif